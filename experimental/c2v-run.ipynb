{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code2vec model\n",
    "## Выглядит так: \n",
    "![code2vec](img/code2vec_network.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы существуем в папке experimental, поэтому нужно вернуться в корень репозитория, чтобы иметь доступ к vocabulary.py и path_context_reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ruslan/Documents/course-project-TiMP/code2var\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовая инициализация необходимых для работы переменных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Creating vocab from dataset/java-small/java-small.c2v.dict\n",
      "Loading frequency dicts from dataset/java-small/java-small.c2v.dict\n",
      "Loading token freq dict\n",
      "Loading path freq dict\n",
      "Loading target freq dict\n",
      "Creating token vocab\n",
      "Creating vocab from frequency dictionary of 1651196 elements\n",
      "Created token vocab\n",
      "Creating path vocab\n",
      "Creating vocab from frequency dictionary of 1582063 elements\n",
      "Created path vocab\n",
      "Creating target vocab\n",
      "Creating vocab from frequency dictionary of 118171 elements\n",
      "Created target vocab\n",
      "Created all vocabs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "import os\n",
    "import datetime\n",
    "import config\n",
    "import numpy as np\n",
    "from vocabulary import Code2VecVocabs\n",
    "from path_context_reader import PathContextReader, ReaderInputTensors\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "config.config.CREATE_VOCAB = True\n",
    "config.config.TRAINING_FREQ_DICTS_PATH = \"dataset/java-small/java-small.c2v.dict\"\n",
    "c2v_vocabs = Code2VecVocabs()\n",
    "pcr = PathContextReader(is_train=True, vocabs=c2v_vocabs, csv_path=\"dataset/java-small/java-small.train_vec.csv\")\n",
    "dataset = pcr.get_dataset()\n",
    "#init lookups\n",
    "c2v_vocabs.target_vocab.get_word_to_index_lookup_table()\n",
    "c2v_vocabs.token_vocab.get_word_to_index_lookup_table()\n",
    "c2v_vocabs.path_vocab.get_word_to_index_lookup_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Константы, которые потом будут помещены в config.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIMENSION = 100\n",
    "DROPOUT_KEEP_RATE = 0.75\n",
    "TOKEN_VOCAB_SIZE = c2v_vocabs.token_vocab.lookup_table_word_to_index.size().numpy()\n",
    "TARGET_VOCAB_SIZE=c2v_vocabs.target_vocab.lookup_table_word_to_index.size().numpy()\n",
    "PATH_VOCAB_SIZE = c2v_vocabs.path_vocab.lookup_table_word_to_index.size().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переформатировать dataset для подачи tuple(x, y) в code2vec. x- tuple из путей-контекстов и имён функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x : ((x.path_source_token_indices, x.path_indices, x.path_target_token_indices, x.target_index), x.target_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём модели для эмбедов token-ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source_token_embed = tf.keras.Input(shape = (config.config.MAX_CONTEXTS,), name=\"input_source_token\")\n",
    "input_target_token_embed = tf.keras.Input(shape = (config.config.MAX_CONTEXTS,), name=\"input_target_token\")\n",
    "token_embed = tf.keras.layers.Embedding(input_dim = TOKEN_VOCAB_SIZE, \n",
    "                                    output_dim=EMBED_DIMENSION,\n",
    "                                    embeddings_initializer='uniform',\n",
    "                                    name=\"token_embed\") \n",
    "token_source_embed_model = tf.keras.Sequential([input_source_token_embed, token_embed])\n",
    "token_target_embed_model = tf.keras.Sequential([input_target_token_embed, token_embed])\n",
    "print(token_source_embed_model.summary())\n",
    "print(token_target_embed_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём модель для эмбедов путей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_paths_embed = tf.keras.Input(shape=(config.config.MAX_CONTEXTS,), name=\"input_paths\")\n",
    "paths_embed = tf.keras.layers.Embedding(input_dim=PATH_VOCAB_SIZE, output_dim=EMBED_DIMENSION, embeddings_initializer='uniform', name=\"paths_embed\")\n",
    "path_embed_model = tf.keras.Sequential([input_paths_embed, paths_embed])\n",
    "print(path_embed_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная модель code2vec, то, что работает уже с эмбедами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concatenated_embeds = tf.keras.layers.Concatenate(name=\"concatenated_embeds\")([token_source_embed_model.output, path_embed_model.output, token_target_embed_model.output])\n",
    "\n",
    "droped_embeds = tf.keras.layers.Dropout(1-DROPOUT_KEEP_RATE)(concatenated_embeds)\n",
    "flatten_embeds = tf.keras.layers.Reshape((-1, 3*EMBED_DIMENSION), name=\"flatten_embeds\")(droped_embeds)\n",
    "combined_context_vector = tf.keras.layers.Dense(3*EMBED_DIMENSION, activation='tanh', name=\"combined_context_vector\")(flatten_embeds)\n",
    "сontext_weights = tf.keras.layers.Dense(1, activation='softmax', name=\"context_weights\")(combined_context_vector)\n",
    "attention_weights = tf.keras.layers.Reshape((-1, config.config.MAX_CONTEXTS, 1), name=\"attention_weights\")(сontext_weights)\n",
    "\n",
    "batched_embed = tf.keras.layers.Reshape((-1, config.config.MAX_CONTEXTS, 3*EMBED_DIMENSION), name=\"batched_embed\") (combined_context_vector)\n",
    "code_vectors = tf.keras.layers.Multiply()([batched_embed, attention_weights])\n",
    "code_vectors = tf.keras.backend.squeeze(code_vectors, axis=1)\n",
    "code_vectors = tf.keras.backend.sum(code_vectors, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нововведение, определяем вероятность каждого из target softmax-ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_targets = tf.keras.layers.Dense(TARGET_VOCAB_SIZE, activation=\"softmax\", name=\"possible_targets\")(code_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эмбед для target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_target_embed = tf.keras.Input(shape=(1,), dtype=tf.int64, name=\"target\")\n",
    "target_embed = tf.keras.layers.Embedding(input_dim=TARGET_VOCAB_SIZE, \n",
    "                                        output_dim=3*EMBED_DIMENSION,\n",
    "                                        embeddings_initializer='uniform',\n",
    "                                        name=\"target_embed\") (input_target_embed)\n",
    "target_embed = tf.keras.backend.squeeze(target_embed, axis=1)\n",
    "target_embed_model = tf.keras.Model(inputs=input_target_embed, outputs=target_embed)\n",
    "print(target_embed_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Финальный этап - подсчёт logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logits = tf.keras.layers.Dot([1, 1],name=\"logits\")([code_vectors, target_embed_model.output])\n",
    "batch_size = tf.cast(tf.shape(input_target_embed)[0], tf.float32)\n",
    "\n",
    "inputs = [token_source_embed_model.input, path_embed_model.input, token_target_embed_model.input, target_embed_model.input]\n",
    "code2vec = tf.keras.Model(inputs=inputs, outputs=possible_targets)\n",
    "print(code2vec.summary())\n",
    "tf.keras.utils.plot_model(code2vec, show_shapes=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_loss(labels, logits):\n",
    "    \"\"\"custom loss function\"\"\"\n",
    "    return tf.keras.backend.sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.reshape(labels, [-1]), logits=logits)) / config.config.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "code2vec.compile(optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'],  loss=\"sparse_categorical_crossentropy\")\n",
    "code2vec.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просто чтобы посмотреть как оно там живёт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    280/Unknown - 779s 3s/step - loss: 7.7905 - accuracy: 0.1859"
     ]
    }
   ],
   "source": [
    "code2vec.fit(dataset, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "code2vec.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_c2v = tf.keras.Model(inputs=inputs, outputs=code_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset).get_next()\n",
    "a, a_1 = eval_c2v(it[0]), it[1]\n",
    "it = iter(dataset).get_next()\n",
    "b, b_1 = eval_c2v(it[0]), it[1]\n",
    "it = iter(dataset).get_next()\n",
    "c, c_1 = eval_c2v(it[0]), it[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1\n",
    "r_1 = a[0]\n",
    "r_2 = a[1]\n",
    "r_3 = a[2]\n",
    "def cos(x, y):\n",
    "    return np.dot(x, y) / (np.sqrt(np.dot(x, x)) * np.sqrt(np.dot(y, y)))\n",
    "\n",
    "print(cos(r_1, r_2))\n",
    "print(cos(r_2, r_3))\n",
    "print(cos(r_1, r_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2v_vocabs.target_vocab.word_to_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
