{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 5 status\n",
    "\n",
    "План:\n",
    "1. Список влитых PR\n",
    "2. Результат работы скомпилированного кода\n",
    "3. Список фичей на следующую неделю\n",
    "\n",
    "## Влитые PR в master.\n",
    "1. vocab -> master\n",
    "\n",
    "Написан файл vocabulary.py и тесты к нему. Файл отвевчает за создание словарей индекс-значение и значение-индекс из предобработанных словарей частот вхождения слов.\n",
    "\n",
    "## Демонстрация работы программы\n",
    "\n",
    "### Вызов скрипта, который выполнит предобработку датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$1 (file:/usr/share/maven/lib/guice.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)\n",
      "WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$1\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Obfuscating flag set  true\n",
      "Processing train files from dataset/java-small/training/\n",
      "Done. Generated dataset/java-small/java-small.train.paths.code2vec\n",
      "Processing test files from dataset/java-small/test/\n",
      "Done. Generated dataset/java-small/java-small.test.paths.code2vec\n",
      "Processing train files from dataset/java-small/validation/\n",
      "Done. Generated dataset/java-small/java-small.validation.paths.code2vec\n",
      "Processing train files from dataset/java-small/training/\n",
      "Done. Generated dataset/java-small/java-small.train.paths.code2var\n",
      "Processing test files from dataset/java-small/test/\n",
      "Done. Generated dataset/java-small/java-small.test.paths.code2var\n",
      "Processing train files from dataset/java-small/validation/\n",
      "Done. Generated dataset/java-small/java-small.validation.paths.code2var\n",
      "Generating vocabularies from dataset/java-small/java-small.train.paths.code2vec\n",
      "processed file + dataset/java-small/java-small.test.paths.code2vec\n",
      "generated file + dataset/java-small/java-small.csv\n",
      "processed file + dataset/java-small/java-small.validation.paths.code2vec\n",
      "generated file + dataset/java-small/java-small.csv\n",
      "processed file + dataset/java-small/java-small.train.paths.code2vec\n",
      "generated file + dataset/java-small/java-small.csv\n",
      "Frequency dictionaries saved to: dataset/java-small/java-small.c2v.dict\n"
     ]
    }
   ],
   "source": [
    "! cd ../ && ./preprocess.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Пример полученных словарей\n",
    "\n",
    "target - строка результата, который мы должны получить: имя функции или имя переменной.\n",
    "\n",
    "path - Хэш путя, который участвует в контекстном векторе лист-путь-лист\n",
    "\n",
    "token - лист в контекстном векторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--token--\n",
      "('readint', '68\\n')\n",
      "('updateimpl', '4\\n')\n",
      "('xeavaxzyfgct', '23\\n')\n",
      "('bfnrvajxtlaf', '97\\n')\n",
      "('ldlpoormopxa', '15\\n')\n",
      "('fddqqmftgsff', '113\\n')\n",
      "('hasremaining', '21\\n')\n",
      "('gciddtlpnuct', '37\\n')\n",
      "('replayingclversionmessagingversioncompression', '19\\n')\n",
      "('mlhxitgglpke', '114\\n')\n",
      "--path--\n",
      "('-971436050', '1\\n')\n",
      "('1344848348', '1\\n')\n",
      "('855198884', '2\\n')\n",
      "('-180894139', '3\\n')\n",
      "('2138400090', '4\\n')\n",
      "('784961679', '2\\n')\n",
      "('1827530239', '1\\n')\n",
      "('977506677', '1\\n')\n",
      "('1981396214', '3\\n')\n",
      "('-682202921', '2\\n')\n",
      "--target--\n",
      "('get|active|content|size', '1\\n')\n",
      "('make|mutation', '1\\n')\n",
      "('get|ticker|symbol', '3\\n')\n",
      "('await|management|tasks|completion', '1\\n')\n",
      "('to|model', '1\\n')\n",
      "('delete|persisted|model', '3\\n')\n",
      "('get|account|service', '1\\n')\n",
      "('get|model|class', '4\\n')\n",
      "('get|sic|code', '3\\n')\n",
      "('test|recovery', '3\\n')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from typing import Dict\n",
    "\n",
    "dataset_path = \"../dataset/java-small/java-small.c2v.dict\"\n",
    "\n",
    "with open(dataset_path, \"rb\") as file:\n",
    "    token = pickle.load(file)\n",
    "    path = pickle.load(file)\n",
    "    target = pickle.load(file)\n",
    "\n",
    "\n",
    "print (\"--token--\")\n",
    "for el in list(token.items())[:10]:\n",
    "    print (el)\n",
    "print (\"--path--\")\n",
    "for el in list(path.items())[:10]:\n",
    "    print (el)\n",
    "print (\"--target--\")\n",
    "for el in list(target.items())[:10]:\n",
    "    print (el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация индексированных словарей. Файл vocabulary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/java-small/java-small.c2v.dict\n",
      "Creating vocab from ../dataset/java-small/java-small.c2v.dict\n",
      "Loading frequency dicts from ../dataset/java-small/java-small.c2v.dict\n",
      "Loading token freq dict\n",
      "Loading path freq dict\n",
      "Loading target freq dict\n",
      "Creating token vocab\n",
      "Creating vocab from frequency dictionary of 2301 elements\n",
      "Created token vocab\n",
      "Creating path vocab\n",
      "Creating vocab from frequency dictionary of 23541 elements\n",
      "Created path vocab\n",
      "Creating target vocab\n",
      "Creating vocab from frequency dictionary of 359 elements\n",
      "Created target vocab\n",
      "Created all vocabs\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from vocabulary import Code2VecVocabs\n",
    "\n",
    "config.config.CREATE_VOCAB = True\n",
    "config.config.TRAINING_FREQ_DICTS_PATH = dataset_path\n",
    "print (config.config.TRAINING_FREQ_DICTS_PATH)\n",
    "c2v_vocabs = Code2VecVocabs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--target--\n",
      "('get|active|content|size', 0)\n",
      "('make|mutation', 1)\n",
      "('await|management|tasks|completion', 2)\n",
      "('to|model', 3)\n",
      "('get|account|service', 4)\n",
      "('discard|completed|segments', 5)\n",
      "('remove|clean|from|dirty', 6)\n",
      "('to|json|string', 7)\n",
      "('test|discarded|run', 8)\n",
      "('test|find|all', 9)\n",
      "--path--\n",
      "('-971436050', 0)\n",
      "('1344848348', 1)\n",
      "('1827530239', 2)\n",
      "('977506677', 3)\n",
      "('1993562940', 4)\n",
      "('78453073', 5)\n",
      "('894458789', 6)\n",
      "('552695542', 7)\n",
      "('807211546', 8)\n",
      "('-1815559921', 9)\n",
      "--token--\n",
      "('getchannel', 0)\n",
      "('inorderinclusiontester', 1)\n",
      "('xf', 2)\n",
      "('typeparser', 3)\n",
      "('internalclose', 4)\n",
      "('call', 5)\n",
      "('servicecontextthreadlocal', 6)\n",
      "('mutationinitiator', 7)\n",
      "('deprecated', 8)\n",
      "('compressionparams', 9)\n"
     ]
    }
   ],
   "source": [
    "print (\"--target--\")\n",
    "for el in list(c2v_vocabs.target_vocab.word_to_index.items())[:10]:\n",
    "    print(el)\n",
    "\n",
    "print (\"--path--\")\n",
    "for el in list(c2v_vocabs.path_vocab.word_to_index.items())[:10]:\n",
    "    print(el)\n",
    "\n",
    "print (\"--token--\")\n",
    "for el in list(c2v_vocabs.token_vocab.word_to_index.items())[:10]:\n",
    "    print(el)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}